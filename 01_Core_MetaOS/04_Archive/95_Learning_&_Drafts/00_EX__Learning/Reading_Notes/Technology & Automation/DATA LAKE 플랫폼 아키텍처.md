
[[Data_Lake]]
## 등장배경
RAW DATA를 원천 데이터 포맷 그대로 적재하는 DATA Lake 개념의 필요성 주장 사용자가 원하는 형태와 방식으로 자유롭고 유연하게 분석하는 방향으로 변해야 한다는 것이다.

데이터 웨어하우스는 데이터 분석을 위해 사전에 데이터를 모델링하여 적재하는 Schema-on-Write라고 부르는 특성을 가진다.
- 사용자가 실데이터를 분석하기전 분석 요건을 정의하는 것은 쉽지 않다
- 분석 요건도 계속해서 변경해야만 한다.
- 사용자가 요청한 데이터 분석 요건이 구현되기까지 기다려야 한다.
- '데이터 웨어하우스'의 성능과 데이터 정합성이 저하
- DA담당자를 통해야만 한다
- 이러한 문제점이 있다.

DATA LAKE는 Schema-on-Read특성을 가진다
- 분석 요건을 정이할 필요가 없다
- 본인이 직접 Self-Service로 데이터를 분석
- 데이터 중복을 최소화하여 적재 공간을 효율적으로 관리
- DATA LAKE라는 개념이 2010년으로 10년이 지난지금 국내에서는 널리 알려져 있지 못한다.
- 상당수 글로벌 기업들이 어떤 형태로든 data lake를 구축하는 프로젝트를 시작 -> 빅데이터의 활용 경쟁에서 이길려고함

## 개념
전사의 주요한 Raw Data 뿐만 아니라 사용자 가공 데이터까지 수집 하고 서비스하며, 모든 구성원들이 Self-Service를 통해 손쉽게 데이터를 활용할 수 있도록 서비스하는 플랫폼

## 구성요소
논리적 역할 에 따른 "**영역(Layer)**" 각 영역별 세부 기능에 따른 "**구성요소(Component)**" 로 구분
![[Pasted image 20250515013441.png]]
+ '기능 구성도'란 전체 시스템의 기능적 구성요소를 한눈에 파악할 수 있도록 구성한 '논리 아키텍처'의 한 유형임.
일단 수집하여 data lake에 적재
수집 레이어는 관계형 데이터 베이스 (CSV,TSV)와 같은 정형 텍스트 데이터를 포함하여 별도의 처리 없이 곧바로 활용가능한 '정형 데이터'수집
파싱을 통해 필요한 데이터를 추출하여 활용해야 하는 '반정형 데이터' 수집
일정한 규칙이 없어 별도의 프로세싱을 통해 활용할 수 잇는 데이터를 만들어 내야 하는 '비정형 데이터'도 수집

원천 시스템으로 부터 수집한 원본 데이터는 '적재 layer'에 저장 보관
DATA Lake의 주 저장소는 "람다 아키텍처"를 기준으로 했을때, '하둡 분산 파일 시스템 HDFS'이며 편의성제공을 위해 데이터 유형에 따라 추가적인 적재소를 보유 할 수 있다
* '람다 아키텍처'는 배치와 실시간 프로세싱을 모두 수용하는 구조

큐 방식의 '메시지 브로커(Message Broker)'-> 메시지의 형태 (포맷)을 변경, 원천과 타깃의 부하를 분산시키는 역할도 함께 수행

관계형 데이터베이스가 있으며 '기준정보'나'마스터 데이터'를 이와 같은 적재소에 저장하여 서비스

그 다음 적재소로 NoSQL 데이터베이스가 있다. 대용량 Raw Data를 미리 가공하여 NoSQL DB에 적재, 사용자의 요청이 있을 경우, 빠른 속도로 제공하기 위한 '데이터 마트'의 용도로 활용가능

최상단에 위치한 '사용자 Self-Service Layer'은 UI를 통해 직접 필요한 데이터를 찾고,조회하고,전처리하고 분석하는 등의 서비스를 제공하는 역할을 수행

## 아키텍쳐 설계 기본 원칙
정책(Policy)아닌, 어떤 경우에도 항상 지켜야 할 기업의 가치(Value)를 담은 '설계 지침(Design Guideline)'을 정의하는것

## 아키텍쳐 설계 방향
개념 아키텍처'(Conceptual Architecture)'를 정의해야한다. Data Lake 플랫폼의 추진 목적과 전체 구성요소를 한 페이지로 도식화하여 표현하는것

## 람다 아키텍쳐 vs 카파 아키텍처
어떤 기반으로 할건지 결정해야한다.
data lake플랫폼의 주 저장소를 무엇으로 할것인지에 대한 결정을 해야한다.
(비교적 적은 비용으로 많은 용량의 데이터를 적재할 수 있어야 한다.)